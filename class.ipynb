{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edddc076",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR class PIPELINE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d95ce",
   "metadata": {},
   "source": [
    "***DON'T EDIT THIS CODE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64fe5c1",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO READ DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7816b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class HDFSConnector:\n",
    "\n",
    "    def fetch(spark, config):\n",
    "        ################### INPUT HADOOP HOST PORT TO CONNECT WITH ###############################\n",
    "        hdfs_server = str(os.environ['HDFS_SERVER'])\n",
    "        hdfs_port = int(os.environ['HDFS_PORT'])\n",
    "        df = spark.read.options(header='true', inferschema='true').csv(\n",
    "            f\"hdfs://{hdfs_server}:{hdfs_port}{eval(config)['url']}\", header='true')\n",
    "        display(df.limit(2).toPandas())\n",
    "        return df\n",
    "\n",
    "    def put(df, spark, config):\n",
    "        return df.write.format('csv').options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                                              delimiter=eval(config)[\"delimiter\"]).save((\"%s %s\") % (datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")+\"_\", eval(config)['url']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3e26c",
   "metadata": {},
   "source": [
    "***TRANSFORMATIONS FUNCTIONS THAT WILL BE APPLIED ON DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import mean, stddev, min, max, col\n",
    "\n",
    "\n",
    "class CleanseData:\n",
    "    # def __init__(self,df):\n",
    "    #     #print()\n",
    "\n",
    "    def cleanValueForFE(self, value):\n",
    "        if value == None:\n",
    "            return \"\"\n",
    "        elif str(value) == 'nan':\n",
    "            return \"nan\"\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "    def replaceByMean(self, feature, df, mean_=-1):\n",
    "        df1 = df\n",
    "        df1 = df1.dropna()\n",
    "        meanValue = self.cleanValueForFE(df1.select(\n",
    "            mean(col(feature.name)).alias('mean')).collect()[0][\"mean\"])\n",
    "        df = df.fillna(meanValue, subset=[feature.name])\n",
    "        df.withColumn(feature.name, when(col(feature.name) == \" \",\n",
    "                      meanValue).otherwise(col(feature.name).cast(\"Integer\")))\n",
    "        return df\n",
    "\n",
    "    def replaceByMax(self, feature, df, max_=-1):\n",
    "        df1 = df\n",
    "        df1 = df1.dropna()\n",
    "        maxValue = self.cleanValueForFE(df1.select(\n",
    "            max(col(feature.name)).alias('max')).collect()[0][\"max\"])\n",
    "        df = df.fillna(maxValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", maxValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceByMin(self, feature, df, min_=-1):\n",
    "        df1 = df\n",
    "        df1 = df1.dropna()\n",
    "        minValue = self.cleanValueForFE(df1.select(\n",
    "            min(col(feature.name)).alias('min')).collect()[0][\"min\"])\n",
    "        df = df.fillna(minValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", minValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceByStandardDeviation(self, feature, df, stddev_=-1):\n",
    "        df1 = df\n",
    "        df1 = df1.dropna()\n",
    "        stddevValue = self.cleanValueForFE(df1.select(\n",
    "            stddev(col(feature.name)).alias('stddev')).collect()[0][\"stddev\"])\n",
    "        df = df.fillna(stddevValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", stddevValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceDateRandomly(self, feature, df):\n",
    "        df1 = df\n",
    "        df1 = df1.dropna()\n",
    "        fillValue = self.cleanValueForFE(\n",
    "            df.where(col(feature.name).isNotNull()).head(1)[0][feature.name])\n",
    "        df = df.fillna(str(fillValue), subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", fillValue).otherwise(col(feature.name)))\n",
    "        # print(\"CleanseData:replaceDateRandomly Schema : \", df.#printSchema())\n",
    "        return df\n",
    "\n",
    "    def replaceNullValues(self, fList, df):\n",
    "        featuresList = df.schema.fields\n",
    "        for featureObj in fList:\n",
    "            for feat in featuresList:\n",
    "                if featureObj[\"feature\"] in feat.name:\n",
    "                    featureName = feat\n",
    "                    if \"mean\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMean(featureName, df)\n",
    "                    elif \"max\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMax(featureName, df)\n",
    "                    elif \"min\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMin(featureName, df)\n",
    "                    elif \"stddev\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByStandardDeviation(featureName, df)\n",
    "                    elif \"random\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceDateRandomly(featureName, df)\n",
    "        return df\n",
    "\n",
    "\n",
    "def StringIndexerTransform(df, params, transformationData={}):\n",
    "    dfReturn = df\n",
    "    feature = params[\"feature\"]\n",
    "\n",
    "    dfReturn = dfReturn.fillna({feature: ''})\n",
    "    outcol = feature + \"_stringindexer\"\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=feature, outputCol=outcol, handleInvalid=\"skip\")\n",
    "    indexed = indexer.fit(dfReturn).transform(dfReturn)\n",
    "    dfReturn = indexed\n",
    "    distinct_values_list = dfReturn.select(\n",
    "        outcol).distinct().rdd.map(lambda r: r[0]).collect()\n",
    "    len_distinct_values_list = len(distinct_values_list)\n",
    "    if len_distinct_values_list <= 4:\n",
    "        changed_type_df = dfReturn.withColumn(\n",
    "            outcol, dfReturn[outcol].cast(IntegerType()))\n",
    "        return changed_type_df\n",
    "    return dfReturn\n",
    "\n",
    "\n",
    "class TransformationMain:\n",
    "    # TODO: change df argument in run with following\n",
    "    def run(transformationDF, config):\n",
    "        configObj = json.loads(config)\n",
    "        featureData = configObj[\"FE\"]\n",
    "        transformationDF = CleanseData().replaceNullValues(featureData, transformationDF)\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'Region Code', 'transformation_label': 'String Indexer'}], 'feature': 'Region Code', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "                                                  'count': '500', 'mean': '', 'stddev': '', 'min': 'ATL', 'max': 'SFO', 'missing': '0', 'distinct': '10'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'Region Code'}, {'feature_label': 'Region Code', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('Region Code')\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'State Code', 'transformation_label': 'String Indexer'}], 'feature': 'State Code', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '500', 'mean': '', 'stddev': '', 'min': 'AK ', 'max': 'WY ', 'missing': '0', 'distinct': '52'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'State Code'}, {'feature_label': 'State Code', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('State Code')\n",
    "        display(transformationDF.limit(2).toPandas())\n",
    "        return transformationDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d848e91",
   "metadata": {},
   "source": [
    "***AUTOML FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b34d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyspark\n",
    "\n",
    "\n",
    "def functionClassification(sparkDF, listOfFeatures, label):\n",
    "    sparkDF.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = (sparkDF.toPandas())\n",
    "    X = (df.drop(label, axis=1))[listOfFeatures].values\n",
    "    y = df[label].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1, test_size=0.1)\n",
    "    tpotModel = TPOTClassifier(verbosity=3, n_jobs=-1, generations=10, max_time_mins=5,\n",
    "                               population_size=15, use_dask=True)\n",
    "    tpotModel.fit(X_train, y_train)\n",
    "    display(\" Accuracy of Model : %s\" % tpotModel.score(X_test, y_test))\n",
    "    data = {'model': tpotModel,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'label': label,\n",
    "            'columnNames': listOfFeatures}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ccbeb",
   "metadata": {},
   "source": [
    "***READING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2003a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CREATE SPARK SESSION ############################ ENTER YOUR SPARK MASTER IP AND PORT TO CONNECT TO SERVER ################\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[1]').getOrCreate()\n",
    "#%run classHooks.ipynb\n",
    "try:\n",
    "\t#sourcePreExecutionHook()\n",
    "\n",
    "\tssadisability = HDFSConnector.fetch(spark, \"{'url': '/FileStore/platform/uploadedSourceFiles/ssa_disability.csv', 'filename': 'ssa_disability.csv', 'delimiter': ',', 'file_type': 'Delimeted', 'is_header': 'Use Header Line', 'domain': 'http://172.31.59.158', 'port': '40070', 'dirPath': '/FileStore/platform', 'server_url': '/nexusMax/NexusMaxPlatform/uploads/platform/'}\")\n",
    "\t#sourcePostExecutionHook(ssadisability)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n",
    "#spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae36a6a",
   "metadata": {},
   "source": [
    "***TRANSFORMING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d56bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run classHooks.ipynb\n",
    "try:\n",
    "\t#transformationPreExecutionHook()\n",
    "\n",
    "\tclassautofe = TransformationMain.run(ssadisability,json.dumps( {\"FE\": [{\"transformationsData\": [{\"feature_label\": \"Region Code\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"Region Code\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"500\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"ATL\", \"max\": \"SFO\", \"missing\": \"0\", \"distinct\": \"10\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Region Code\"}, {\"transformationsData\": [{\"feature_label\": \"State Code\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"State Code\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"500\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"AK \", \"max\": \"WY \", \"missing\": \"0\", \"distinct\": \"52\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"State Code\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Date\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"2005.32\", \"stddev\": \"2.78\", \"min\": \"2001\", \"max\": \"2010\", \"missing\": \"0\"}, \"updatedLabel\": \"Date\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Population age 18-64*\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"3615996.39\", \"stddev\": \"4045541.47\", \"min\": \"308796\", \"max\": \"23765508\", \"missing\": \"0\"}, \"updatedLabel\": \"Population age 18-64*\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"SSA Disability Beneficiaries  age 18-64*\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"194976.85\", \"stddev\": \"197614.39\", \"min\": \"11780\", \"max\": \"1125410\", \"missing\": \"0\"}, \"updatedLabel\": \"SSA Disability Beneficiar...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Percent of Adult Population Receiving SSA Adult Disability Benefits\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"5.56\", \"stddev\": \"1.78\", \"min\": \"2.6\", \"max\": \"12.42\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Percent of Adult Populati...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eligible Adult Population*\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"3421019.54\", \"stddev\": \"3854803.68\", \"min\": \"297016\", \"max\": \"22640098\", \"missing\": \"0\"}, \"updatedLabel\": \"Eligible Adult Population...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Adult Receipts\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"41800.94\", \"stddev\": \"43419.25\", \"min\": \"2459\", \"max\": \"249112\", \"missing\": \"0\"}, \"updatedLabel\": \"Adult Receipts\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eligible Adult Population Filing Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"1.25\", \"stddev\": \"0.4\", \"min\": \"0.55\", \"max\": \"2.64\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eligible Adult Population...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Favorable Adult Determinations\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"14225.64\", \"stddev\": \"16058.22\", \"min\": \"764\", \"max\": \"97457\", \"missing\": \"0\"}, \"updatedLabel\": \"Favorable Adult Determina...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eligible Adult Population Allowance Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"0.42\", \"stddev\": \"0.11\", \"min\": \"0.16\", \"max\": \"1.08\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eligible Adult Population...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"All Adult Determinations\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"40124.45\", \"stddev\": \"41920.61\", \"min\": \"2450\", \"max\": \"233656\", \"missing\": \"0\"}, \"updatedLabel\": \"All Adult Determinations\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Adult Favorable  Determination Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"36.61\", \"stddev\": \"7.68\", \"min\": \"21.5\", \"max\": \"66.22\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Adult Favorable  Determin...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Population under age 18*\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"1412077.88\", \"stddev\": \"1661249.37\", \"min\": \"0\", \"max\": \"9435682\", \"missing\": \"0\"}, \"updatedLabel\": \"Population under age 18*\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"SSI Disabled Child (DC) Beneficiaries*\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"20136.24\", \"stddev\": \"23054.02\", \"min\": \"0\", \"max\": \"120530\", \"missing\": \"0\"}, \"updatedLabel\": \"SSI Disabled Child (DC) B...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Percent of Population under age 18 Receiving SSI DC Benefits\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"1.38\", \"stddev\": \"0.72\", \"min\": \"0.0\", \"max\": \"3.97\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Percent of Population und...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eligible Child Population*\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"1391941.64\", \"stddev\": \"1639951.73\", \"min\": \"0\", \"max\": \"9337164\", \"missing\": \"0\"}, \"updatedLabel\": \"Eligible Child Population...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"SSI Disabled Child (DC) Receipts\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"7951.52\", \"stddev\": \"8678.8\", \"min\": \"0\", \"max\": \"46852\", \"missing\": \"0\"}, \"updatedLabel\": \"SSI Disabled Child (DC) R...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eligible Child Population Filing Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"0.55\", \"stddev\": \"0.31\", \"min\": \"0.0\", \"max\": \"1.69\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eligible Child Population...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Favorable SSI Child (DC) Determinations\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"3282.43\", \"stddev\": \"3806.37\", \"min\": \"0\", \"max\": \"20286\", \"missing\": \"0\"}, \"updatedLabel\": \"Favorable SSI Child (DC) ...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eligible Child Population Allowance Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"0.23\", \"stddev\": \"0.11\", \"min\": \"0.0\", \"max\": \"0.68\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eligible Child Population...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"All SSI Disabled Child Determinations\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"7742.08\", \"stddev\": \"8458.88\", \"min\": \"0\", \"max\": \"42956\", \"missing\": \"0\"}, \"updatedLabel\": \"All SSI Disabled Child De...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"SSI Disabled Child Allowance Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"45.83\", \"stddev\": \"11.87\", \"min\": \"0.0\", \"max\": \"79.46\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"SSI Disabled Child Allowa...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"All Determinations\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"47866.53\", \"stddev\": \"50030.59\", \"min\": \"2731\", \"max\": \"269121\", \"missing\": \"0\"}, \"updatedLabel\": \"All Determinations\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"All Favorable Determinations\", \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"type\": \"numeric\", \"replaceby\": \"mean\", \"selected\": \"True\", \"stats\": {\"count\": \"500\", \"mean\": \"17508.07\", \"stddev\": \"19727.76\", \"min\": \"894\", \"max\": \"114527\", \"missing\": \"0\"}, \"updatedLabel\": \"All Favorable Determinati...\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Favorable Determination Rate\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"500\", \"mean\": \"37.92\", \"stddev\": \"7.46\", \"min\": \"22.98\", \"max\": \"65.55\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Favorable Determination R...\"}]}))\n",
    "\n",
    "\t#transformationPostExecutionHook(classautofe)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44b074",
   "metadata": {},
   "source": [
    "***TRAIN MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run classHooks.ipynb\n",
    "try:\n",
    "\t#mlPreExecutionHook()\n",
    "\n",
    "\tdataAutoML=functionClassification(classautofe, [\"Date\", \"Population age 18-64*\", \"SSA Disability Beneficiaries  age 18-64*\", \"Percent of Adult Population Receiving SSA Adult Disability Benefits\", \"Eligible Adult Population*\", \"Adult Receipts\", \"Favorable Adult Determinations\", \"Eligible Adult Population Allowance Rate\", \"All Adult Determinations\", \"Adult Favorable  Determination Rate\", \"Population under age 18*\", \"SSI Disabled Child (DC) Beneficiaries*\", \"Percent of Population under age 18 Receiving SSI DC Benefits\", \"Eligible Child Population*\", \"SSI Disabled Child (DC) Receipts\", \"Eligible Child Population Filing Rate\", \"Favorable SSI Child (DC) Determinations\", \"Eligible Child Population Allowance Rate\", \"All SSI Disabled Child Determinations\", \"SSI Disabled Child Allowance Rate\", \"All Determinations\", \"All Favorable Determinations\", \"Favorable Determination Rate\", \"Region Code_stringindexer\", \"State Code_stringindexer\"], \"Eligible Adult Population Filing Rate\")\n",
    "\n",
    "\t#mlPostExecutionHook(dataAutoML)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n",
    "#spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0807cdc",
   "metadata": {},
   "source": [
    "***PREDICT ON TRAINED MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37075932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "try:\n",
    "    model=dataAutoML['model']\n",
    "    X_test=dataAutoML['X_test']\n",
    "    y_test=dataAutoML['y_test']\n",
    "    label=dataAutoML['label']\n",
    "    columnNames=dataAutoML['columnNames']\n",
    "    if label in columnNames:\n",
    "        columnNames.remove(label)\n",
    "    predicted=label+\"_predicted\"\n",
    "    y_predicted=model.predict(X_test)\n",
    "    df =pd.DataFrame(X_test , columns=columnNames)\n",
    "    df[label]=y_test\n",
    "    df[predicted]=y_predicted\n",
    "    columnNames.insert(0,predicted)\n",
    "    columnNames.insert(0,label)\n",
    "    Accuracy = np.round((100 * sklearn.metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)), 1)\n",
    "    F1= np.round(\n",
    "            (100 * sklearn.metrics.f1_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    Precision= np.round((\n",
    "                100 * sklearn.metrics.precision_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    Recall = np.round((\n",
    "                100 * sklearn.metrics.recall_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    display(\" Accuracy of Prediction on test data    : %s\"%Accuracy)\n",
    "    display(\" F1 score of Prediction on test data    : %s\"%F1)\n",
    "    display(\" Precision of Prediction on test data   : %s\"%Precision)\n",
    "    display(\" Recall of Prediction on test data      : %s\"%Recall)\n",
    "    display(df.head())\n",
    "except Exception as ex:\n",
    "    logging.error(ex)\n",
    "\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
